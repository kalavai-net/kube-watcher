############################
### MUST HAVE THESE FIELDS ##
- name: id_field
  value: model_id
  default: model_id
  editable: false
  required: false
  description: "Field that contains the ID of the job"
############################

- name: gpu_backend
  value: "cuda"
  default: "cuda"
  editable: true
  required: false
  description: "Use 'cuda' (nvidia cards) or 'rocm' (AMD cards) backend"

- name: model_name_override
  value: ""
  default: ""
  editable: true
  required: false
  description: "Model name to use (defaults to model_id) during inference"

- name: working_memory
  value: 5
  default: 5
  editable: true
  required: true
  description: "Temporary storage to use to cache model weights (in GB), should be big enough to hold the model weights. All workers should have enough free disk to accommodate the weights."

- name: workers
  value: 1
  default: 1
  editable: true
  required: true
  description: "Number of workers, corresponding to the number of nodes (or machines) that will be used to deploy the model"

- name: model_id
  value: null
  default: null
  editable: true
  required: true
  description: "Huggingface model id to deploy"

- name: lora_modules
  value: ""
  default: ""
  editable: true
  required: false
  description: "LoRa adaptor(s) to load; semi-colon separated list of huggingface repos of the lora adaptors to load"

- name: hf_token
  value: <yout token>
  default: null
  editable: true
  required: true
  description: "Huggingface access token, only required to load gated model weights"

- name: cpus
  value: 2
  default: 2
  editable: true
  required: false
  description: "CPUs to be used per single worker (final one = cpus * workers). Workers should have these many CPUs available."

- name: gpus
  value: 1
  default: 1
  editable: true
  required: false
  description: "GPUs to be used per single worker (final one = gpus * workers). Workers should have these many GPUs available."

- name: memory
  value: 8
  default: 8
  editable: true
  required: false
  description: "RAM memory to be used per single worker (final one = memory * workers). Workers should have these much RAM available."

- name: cuda_gpu_mem_percentage
  value: 100
  default: 100
  editable: true
  required: false
  description: "Maximum memory fraction allowed to be used from the GPU vRAM."

- name: download_worker_weights
  value: "True"
  default: "True"
  editable: true
  required: false
  description: "Whether to pre-download model weights on all workers. If not True, the model is only downloaded in the server node and weights are shared internally."

- name: tool_call_parser
  value: "llama3_json"
  default: "llama3_json"
  editable: true
  required: false
  description: "Tool call parser to use. https://docs.vllm.ai/en/latest/features/tool_calling.html#automatic-function-calling"

- name: template_url
  value: ""
  default: ""
  editable: true
  required: false
  description: "URL of a publicly available template jinja file to use for chat completions (https://docs.vllm.ai/en/v0.8.1/serving/openai_compatible_server.html#chat-template). Some here: https://github.com/vllm-project/vllm/tree/main/examples"

- name: lmcache_max_local_cpu_size
  value: 5.0
  default: 5.0
  editable: true
  required: false
  description: "LMCache: Maximum CPU cache size in GB. See https://docs.lmcache.ai/api_reference/configurations.html"

- name: lmcache_chunk_size
  value: 256
  default: 256
  editable: true
  required: false
  description: "LMCache: chunk size. See https://docs.lmcache.ai/api_reference/configurations.html"

- name: lmcache_local_cpu
  value: "True"
  default: "True"
  editable: true
  required: false
  description: "LMCache: whether or not to use CPU offloading. See https://docs.lmcache.ai/api_reference/configurations.html"

- name: lmcache_max_local_disk_size
  value: 0
  default: 0
  editable: true
  required: false
  description: "LMCache: Maximum disk cache size in GB. See https://docs.lmcache.ai/api_reference/configurations.html"

- name: lmcache_local_disk
  value: null
  default: null
  editable: true
  required: false
  description: "LMCache: Path to local disk cache. Format: “file:///path/to/cache” or null. See https://docs.lmcache.ai/api_reference/configurations.html"

- name: lmcache_remote_url
  value: null
  default: null
  editable: true
  required: false
  description: "LMCache: Remote storage URL. Format: “protocol://host:port” or null. See https://docs.lmcache.ai/api_reference/configurations.html"

- name: extra
  value: "--dtype float16 --enforce-eager"
  default: --dtype float16 --enforce-eager
  editable: true
  required: false
  description: "Extra parameters to pass to the vLLM server. See https://docs.vllm.ai/en/stable/configuration/engine_args.html"

- name: max_retries
  value: 1000
  default: 1000
  editable: true
  required: false
  description: "If the job fails, how many times to retry redeployment"

- name: nodeport
  value: ""
  default: ""
  editable: true
  required: false
  description: "Specify the node port for the service that exposes the job"

## REGISTRAR SIDECAR
- name: litellm_base_url
  value: "http://litellm.default.svc.cluster.local:4000" #"http://192.168.68.67:30219"
  default: "http://litellm.default.svc.cluster.local:4000"
  editable: true
  required: false
  description: "Base URL of the LiteLLM service (central model registry). This can be an external LiteLLM instance or an internal deployment in the pool (default)"

- name: litellm_key
  value: ""
  default: ""
  editable: true
  required: false
  description: "Master key of the LiteLLM service (central model registry)"

- name: litellm_access_group
  value: ""
  default: ""
  editable: true
  required: false
  description: "What access group to assign the model to (ringfencing)"

- name: litellm_kalavai_extras
  value: "{}"
  default: "{}"
  editable: true
  required: false
  description: "Extra information to store in the LiteLLM model registration (must be a dictionary)"

- name: lago_url
  value: ""
  default: ""
  editable: true
  required: false
  description: "Base URL of the Lago service (payment system)"

- name: lago_api_key
  value: ""
  default: ""
  editable: true
  required: false
  description: "Master key of the Lago service"

- name: lago_external_subscription_id
  value: ""
  default: ""
  editable: true
  required: false
  description: "ID of the Lago subscription to send events to"

- name: lago_event_code
  value: ""
  default: ""
  editable: true
  required: false
  description: "Event code to use when submitting event to Lago payment API"

- name: lago_event_interval
  value: ""
  default: ""
  editable: true
  required: false
  description: "Interval in seconds to send the lago event"