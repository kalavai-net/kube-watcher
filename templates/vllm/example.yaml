
- name: litellm_key
  value: ""
  default: ""
  editable: true
  required: false
  description: "Master key of the LiteLLM service (central model registry)"

- name: model_name_override
  value: "Qwen/Qwen3-0.6B"
  default: ""
  editable: true
  required: false
  description: "Model name to use (defaults to model_id) during inference"

- name: working_memory
  value: 10
  default: 5
  editable: true
  required: true
  description: "Temporary storage to use to cache model weights (in GB). All workers should have enough free disk to accommodate the weights."

- name: workers
  value: 1
  default: 1
  editable: true
  required: true
  description: "Number of workers, corresponding to the number of nodes (or machines) that will be used to deploy the model"

- name: model_id
  value: "Qwen/Qwen3-0.6B"
  default: null
  editable: true
  required: true
  description: "Huggingface model id to deploy"

- name: mode
  value: "completion"
  default: "completion"
  editable: true
  required: false
  description: "Mode of the model (useful for health checks): one of [completion, rerank, realtime]. See more: https://docs.litellm.ai/docs/proxy/health"

- name: hf_token
  value: token
  default: null
  editable: true
  required: true
  description: "Huggingface access token, only required to load gated model weights"

- name: cpus
  value: 2
  default: 2
  editable: true
  required: false
  description: "CPUs to be used per single worker (final one = cpus * workers). Workers should have these many CPUs available."

- name: gpus
  value: 1
  default: 1
  editable: true
  required: false
  description: "GPUs to be used per single worker (final one = gpus * workers). Workers should have these many GPUs available."

- name: memory
  value: 8
  default: 8
  editable: true
  required: false
  description: "RAM memory to be used per single worker (final one = memory * workers). Workers should have these much RAM available."

- name: extra
  value: "--max-model-len 4000 --quantization fp8 --enforce-eager"
  default: ""
  editable: true
  required: false
  description: "Extra parameters to pass to the SGLang server. See https://docs.sglang.ai/backend/server_arguments.html"

- name: tool_call_parser
  value: "mistral"
  default: "llama3_json"
  editable: true
  required: false
  description: "Tool call parser to use. https://docs.vllm.ai/en/latest/features/tool_calling.html#automatic-function-calling"
