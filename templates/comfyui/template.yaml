apiVersion: batch.volcano.sh/v1alpha1
kind: Job
metadata:
  name: {{deployment_id}}
  labels:
    # must have this label
    kalavai.job.name: {{deployment_id}}
spec:
  schedulerName: volcano
  plugins:
    env: []
    svc: ["--disable-network-policy=true"]
  maxRetry: -1
  tasks:
  - replicas: 1   # One ps pod specified
    name: server
    maxRetry: -1
    policies:
    - event: PodEvicted
      action: RestartJob
    - event: PodFailed
      action: RestartJob
    - event: TaskCompleted
      action: RestartJob
    - event: Unknown
      action: RestartJob
    template: # Definition of the ps pod
      terminationGracePeriodSeconds: 60
      metadata:
        labels:
          kalavai.job.name: {{deployment_id}}
          role: leader
      spec:
        runtimeClassName: nvidia
        {% if NODE_SELECTORS %}
        affinity:
          nodeAffinity:
            requiredDuringSchedulingIgnoredDuringExecution:
              nodeSelectorTerms:
            {% if NODE_SELECTORS_OPS == "OR" %}
              {% for selector in NODE_SELECTORS %}
              - matchExpressions:
                - key: {{selector.name}}
                  operator: In
                  values:
                  {% for vals in selector.value %}
                  - "{{vals}}"
                  {% endfor %}
              {% endfor %}
            {% else %}
              - matchExpressions:
              {% for selector in NODE_SELECTORS %}
                {% for vals in selector.value %}
                - key: {{selector.name}}
                  operator: In
                  values:
                  - "{{vals}}"
                {% endfor %}
              {% endfor %}
            {% endif %}
        {% endif %}
        containers:
        - name: container
          image: docker.io/kalavai/comfyui-cuda:latest
          imagePullPolicy: Always
          command:
          - sh
          - -c
          - |
            nvidia-smi;
            python3 main.py --listen 0.0.0.0 --port 8188 --multi-user;
          env:
          - name: HF_TOKEN
            value: {{hf_token}}
          ports:
          - containerPort: 8188
            name: container-port
          resources:
            requests:
              cpu: {{cpus}}
              memory: {{memory}}Gi
              nvidia.com/gpu: {{gpus}}
              ephemeral-storage: {{working_memory}}Gi
            limits:
              cpu: {{cpus}}
              memory: {{memory}}Gi
              nvidia.com/gpu: {{gpus}}
              nvidia.com/gpumem-percentage: {{cuda_gpu_mem_percentage}}
              ephemeral-storage: {{working_memory}}Gi
          # readinessProbe:
          #   httpGet:
          #     path: /health
          #     port: 8000
          #   initialDelaySeconds: 5
          #   periodSeconds: 10
        restartPolicy: OnFailure
---
# deploy NodePort to expose model
apiVersion: v1
kind: Service
metadata:
  name: {{deployment_id}}-service
  labels:
    # must have this!
    kalavai.job.name: {{deployment_id}}
spec:
  type: NodePort
  selector:
    role: leader
    kalavai.job.name: {{deployment_id}}
  ports:
    - name: main
      port: 8188
      targetPort: 8188
      protocol: TCP
    {% if nodeport != "" %}
      nodePort: {{nodeport}}
    {% endif %}