apiVersion: batch.volcano.sh/v1alpha1
kind: Job
metadata:
  name: {{deployment_id}}
  labels:
    # must have this label
    kalavai.job.name: {{deployment_id}}
spec:
  schedulerName: volcano
  plugins:
    env: []
    svc: ["--disable-network-policy=true"]
  maxRetry: {{max_retries}}
  tasks:
  - replicas: 1   # One ps pod specified
    name: server
    policies:
    - event: PodEvicted
      action: RestartJob
    - event: PodFailed
      action: RestartJob
    - event: TaskCompleted
      action: RestartJob
    - event: Unknown
      action: RestartJob
    template: # Definition of the ps pod
      metadata:
        annotations:
          # must have these annotations
          {{nouse_gputype}}
          {{use_gputype}}
        labels:
          role: leader
          kalavai.job.name: {{deployment_id}}
      spec:
        runtimeClassName: nvidia
      {% if NODE_SELECTORS %}
        nodeSelector:
        {% for selector in NODE_SELECTORS %}
          {{selector.name}}: {{selector.value}}
        {% endfor %}
      {% endif %}
        containers:
        - name: axolotl-leader
          image: docker.io/bundenth/ray-axolotl:latest
          command:
          - sh
          - -c
          - |
            # Start ray cluster
            RAY_BACKEND_LOG_LEVEL=error /home/ray/workspace/ray_init.sh leader --ray_cluster_size={{workers}} --ray_object_store_memory={{memory * 500000000}};
            sleep 30;
            
            # Run training
            /home/ray/workspace/run_training.sh
          env:
          - name: HF_TOKEN
            value: {{hf_token}}
          ports:
          - containerPort: 8000
            name: axolotl-port
          resources:
            requests:
              cpu: {{cpus}}
              memory: {{memory}}Gi
              nvidia.com/gpu: {{gpus}}
            limits:
              cpu: {{cpus}}
              memory: {{memory}}Gi
              nvidia.com/gpu: {{gpus}}
          volumeMounts:
            - mountPath: /dev/shm
              name: dshm
        volumes:
        - name: dshm
          emptyDir:
            medium: Memory
            sizeLimit: {{memory * 0.5}}Gi
        restartPolicy: OnFailure
  - replicas: {{workers - 1}}
    name: worker
    policies:
    - event: PodEvicted
      action: RestartJob
    - event: PodFailed
      action: RestartJob
    - event: TaskCompleted
      action: RestartJob
    - event: Unknown
      action: RestartJob
    template: # Definition of worker pods
      metadata:
        annotations:
          # must have these annotations
          {{nouse_gputype}}
          {{use_gputype}}
        labels:
          kalavai.job.name: {{deployment_id}}
      spec:
        runtimeClassName: nvidia
      {% if NODE_SELECTORS %}
        nodeSelector:
        {% for selector in NODE_SELECTORS %}
          {{selector.name}}: {{selector.value}}
        {% endfor %}
      {% endif %}
        containers:
        - name: vllm-worker
          image: docker.io/bundenth/ray-axolotl:latest #v1.1.4
          command:
          - sh
          - -c
          - |
            PS_HOST=`cat /etc/volcano/server.host`;
            nvidia-smi;
            RAY_BACKEND_LOG_LEVEL=error /home/ray/workspace/ray_init.sh worker --ray_address=$PS_HOST --ray_port=6379 --ray_object_store_memory={{memory * 500000000}} --ray_block=1
          env:
          - name: HF_TOKEN
            value: {{hf_token}}
          resources:
            requests:
              cpu: {{cpus}}
              memory: {{memory}}Gi
              nvidia.com/gpu: {{gpus}}
            limits:
              cpu: {{cpus}}
              memory: {{memory}}Gi
              nvidia.com/gpu: {{gpus}}
          volumeMounts:
            - mountPath: /dev/shm
              name: dshm
        volumes:
        - name: dshm
          emptyDir:
            medium: Memory
            sizeLimit: {{memory * 0.5}}Gi
        restartPolicy: OnFailure
---
# deploy NodePort to expose model
apiVersion: v1
kind: Service
metadata:
  name: {{deployment_id}}-service
  labels:
    # must have this!
    kalavai.job.name: {{deployment_id}}
spec:
  type: NodePort
  selector:
    role: leader
    kalavai.job.name: {{deployment_id}}
  ports:
    - port: 8000
      targetPort: 8000
      protocol: TCP