apiVersion: batch.volcano.sh/v1alpha1
kind: Job
metadata:
  name: {{deployment_id}}
  labels:
    # must have this label
    kalavai.job.name: {{deployment_id}}
spec:
  queue: default
  #minAvailable: 2
  schedulerName: volcano
  plugins:
    env: []
    svc: []
  maxRetry: {{max_retries}}
  policies: # https://pkg.go.dev/volcano.sh/apis/pkg/apis/bus/v1alpha1
  - event: PodEvicted
    action: RestartJob
  - event: PodFailed
    action: RestartJob
  - event: TaskCompleted
    action: RestartJob
  - event: Unknown
    action: RestartJob
  tasks:
  - replicas: 1   # One ps pod specified
    name: ps
    template: # Definition of the ps pod
      spec:
        {% if NODE_SELECTORS %}
        affinity:
          nodeAffinity:
            requiredDuringSchedulingIgnoredDuringExecution:
              nodeSelectorTerms:
            {% if NODE_SELECTORS_OPS == "OR" %}
              {% for selector in NODE_SELECTORS %}
              - matchExpressions:
                - key: {{selector.name}}
                  operator: In
                  values:
                  {% for vals in selector.value %}
                  - "{{vals}}"
                  {% endfor %}
              {% endfor %}
            {% else %}
              - matchExpressions:
              {% for selector in NODE_SELECTORS %}
                {% for vals in selector.value %}
                - key: {{selector.name}}
                  operator: In
                  values:
                  - "{{vals}}"
                {% endfor %}
              {% endfor %}
            {% endif %}
        {% endif %}
        containers:
        - name: nginx
          # docker image to use as base for each worker
          image: nginx:1.14.2
          # what resources each worker should have
          resources:
            limits:
              cpu: "100m"
              memory: "1Gi"
              nvidia.com/gpu: "1"
              nvidia.com/gpumem-percentage: 0.95
            requests:
              cpu: "50m"
              memory: "1Gi"
              nvidia.com/gpu: "1"
              nvidia.com/gpumem-percentage: 0.95
          ports:
          # what port to make available
          # to make them available through job endpoints, make sure you list the ports in values.yaml, under endpoint_ports
          - containerPort: 8080
        restartPolicy: Never
---
# deploy NodePort to expose model
apiVersion: v1
kind: Service
metadata:
  name: {{deployment_id}}-service
  labels:
    # must have this!
    kalavai.job.name: {{deployment_id}}
spec:
  type: NodePort
  selector:
    role: leader
    kalavai.job.name: {{deployment_id}}
  ports:
    - name: main
      port: 8080
      targetPort: 8080
      protocol: TCP
    {% if nodeport != "" %}
      nodePort: {{nodeport}}
    {% endif %}