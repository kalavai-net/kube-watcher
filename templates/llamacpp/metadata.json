{
    "name": "llama.cpp",
    "description": "LLM inference in C/C++",
    "docs": "https://github.com/ggml-org/llama.cpp",
    "icon": "https://user-images.githubusercontent.com/1991296/230134379-7181e485-c521-4d23-a0d6-f7b3b61ba524.png",
    "info": "With the llama.cpp template you can deploy llama.cpp models on your cluster. Compatible models include those with the GGUF format."
}