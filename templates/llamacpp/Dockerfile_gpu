# syntax=docker/dockerfile:1
FROM nvidia/cuda:12.1.0-cudnn8-devel-ubuntu22.04

ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHON_VERSION=3.10.1
ENV PYTHON_MAJOR=3

WORKDIR /workspace

# install python
RUN apt-get update && \
    apt-get install -y curl git cmake gcc g++ libgomp1 libbz2-dev libev-dev libffi-dev libgdbm-dev liblzma-dev libncurses-dev libreadline-dev libsqlite3-dev libssl-dev make tk-dev wget zlib1g-dev
RUN curl -O https://www.python.org/ftp/python/${PYTHON_VERSION}/Python-${PYTHON_VERSION}.tgz
RUN tar -xvzf Python-${PYTHON_VERSION}.tgz
RUN cd Python-${PYTHON_VERSION} && \
    ./configure \
        --prefix=/opt/python/${PYTHON_VERSION} \
        --enable-shared \
        --enable-optimizations \
        --enable-ipv6 \
        LDFLAGS=-Wl,-rpath=/opt/python/${PYTHON_VERSION}/lib,--disable-new-dtags && \
    make && make install
# install pip
RUN curl -O https://bootstrap.pypa.io/get-pip.py
RUN /opt/python/${PYTHON_VERSION}/bin/python${PYTHON_MAJOR} get-pip.py
# export PATH
ENV PATH=/opt/python/${PYTHON_VERSION}/bin/:$PATH
ENV PATH=/usr/local/cuda/bin:$PATH
ENV LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH

# install python dependencies
RUN python3 -m venv /workspace/env
RUN . /workspace/env/bin/activate && \
    pip3 install huggingface-hub --no-cache-dir

# fetch llama.cpp source
WORKDIR /workspace
RUN git clone https://github.com/ggerganov/llama.cpp.git

COPY run_rpc_worker.sh .
COPY run_api_server.sh .
COPY build.sh .
COPY get_workers_address.sh .
COPY merge.sh .
COPY generate_config.py .

RUN chmod +x /workspace/merge.sh
RUN chmod +x /workspace/run_rpc_worker.sh
RUN chmod +x /workspace/run_api_server.sh
RUN chmod +x /workspace/build.sh
RUN chmod +x /workspace/get_workers_address.sh
