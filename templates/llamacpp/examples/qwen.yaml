

- name: litellm_key
  value: ""
  default: "sk-1234"
  description: "Master key of the LiteLLM service (central registry)"

- name: workers
  value: 1
  default: 1
  editable: true
  required: true
  description: "Number of workers, corresponding to the number of nodes (or machines) that will be used to deploy the model"

- name: backend
  value: "cpu"
  default: "cpu"
  editable: true
  required: true
  description: "Backend to run workers. One of the following: cpu, cuda, rocm"

- name: repo_id
  value: Qwen/Qwen2.5-1.5B-Instruct-GGUF
  default: null
  description: "Huggingface model id to load"

- name: model_filename
  value: "qwen2.5-1.5b-instruct-q2_k.gguf"
  default: "None"
  description: "Specific model file to use (handy for quantized models such as gguf)"

- name: hf_token
  value: <your HF token>
  default: null
  description: "Huggingface token, required to load model weights"

- name: cpus
  value: "2"
  default: "2"
  description: "CPUs per single worker (final one = cpus * num_workers)"

- name: memory
  value: "6"
  default: "4"
  description: "RAM memory per single worker (final one = memory * num_workers)"

- name: rpc_port
  value: "50052"
  default: "50052"
  description: ""

- name: server_extra
  value: ""
  default: ""
  description: ""
