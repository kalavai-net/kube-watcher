{
    "name": "SGLang",
    "description": "SGLang is a fast serving framework for large language models and vision language models.",
    "docs": "https://docs.sglang.ai/",
    "icon": "https://docs.sglang.ai/_static/logo.png",
    "info": "With the SGLang template you can deploy a SGLang server to serve your LLM models in your cluster. Supported models: \n\nLarge language models: DeepSeek (v1, v2, v3/R1), Qwen (3, 3MoE, 2.5, 2 series), Llama (2, 3.x, 4 series), Mistral (Mixtral, NeMo, Small3), Gemma (v1, v2, v3), Phi (Phi-3, Phi-4 series), MiniCPM (v3, 4B), OLMoE (Open MoE), StableLM (3B, 7B), Command-R (Cohere), DBRX (Databricks), Grok (xAI), ChatGLM (GLM-130B family), InternLM 2 (7B, 20B), ExaONE 3 (Korean-English), Baichuan 2 (7B, 13B), XVERSE (MoE), SmolLM (135Mâ€“1.7B), GLM-4 (Multilingual 9B), MiMo (7B series); Multimodal models: Qwen-VL (Qwen2 series), DeepSeek-VL2, Janus-Pro (1B, 7B), MiniCPM-V / MiniCPM-o, Llama 3.2 Vision (11B), LLaVA (v1.5 & v1.6), LLaVA-NeXT (8B, 72B), LLaVA-OneVision, Gemma 3 (Multimodal), Kimi-VL (A3B), Mistral-Small-3.1-24B, Phi-4-multimodal-instruct; Embedding models: Llama/Mistral based (E5EmbeddingModel), GTE (QwenEmbeddingModel), GME (MultimodalEmbedModel), CLIP (CLIPEmbeddingModel), BGE (BgeEmbeddingModel); Reward models: Llama (3.1 Reward / LlamaForSequenceClassification), Gemma 2 (27B Reward / Gemma2ForSequenceClassification), InternLM 2 (Reward / InternLM2ForRewardMode), Qwen2.5 (Reward - Math / Qwen2ForRewardModel), Qwen2.5 (Reward - Sequence / Qwen2ForSequenceClassification)."
}

