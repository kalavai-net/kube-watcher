# example: https://raw.githubusercontent.com/ray-project/ray/master/doc/source/cluster/kubernetes/configs/ray-cluster.gpu.yaml
apiVersion: ray.io/v1
kind: RayCluster
metadata:
  name: {{deployment_id}}
  labels:
    # must have this label
    kalavai.job.name: {{deployment_id}}
  annotations:
    # fault tolerance https://ray-project.github.io/kuberay/guidance/gcs-ft/
    #ray.io/ft-enabled: "true" # <- add this annotation enable GCS FT
    #ray.io/external-storage-namespace: "raycluster-storage" # <- optional, to specify the external storage namespace
spec:
  rayVersion: "{{ray_version}}"
  autoscalerOptions:
    # upscalingMode is "Default" or "Aggressive."
    # Conservative: Upscaling is rate-limited; the number of pending worker pods is at most the size of the Ray cluster.
    # Default: Upscaling is not rate-limited.
    # Aggressive: An alias for Default; upscaling is not rate-limited.
    upscalingMode: {{upscaling_mode}}
    # idleTimeoutSeconds is the number of seconds to wait before scaling down a worker pod which is not using Ray resources.
    idleTimeoutSeconds: {{idle_timeout_seconds}}
  enableInTreeAutoscaling: true
  headGroupSpec:
    serviceType: NodePort
    rayStartParams:
      dashboard-host: "0.0.0.0"
      num-cpus: "0" # avoid workload on head
    template: # Pod template
    {% if enable_auth == "true" %}
      serviceAccountName: {{deployment_id}}-account
    {% endif %}
      metadata:
        labels:
          kalavai.job.name: {{deployment_id}}
      spec: # Pod spec
        priorityClassName: "kalavai-system-priority"
        nodeSelector:
          kalavai/role: server
        restartPolicy: Always
        containers:
        - name: ray-head
          image: docker.io/rayproject/ray:{{ray_version}}-py{{python_version}}-{{cuda_version}}
          imagePullPolicy: IfNotPresent
          resources:
            limits:
              cpu: 2
              memory: 2Gi
            requests:
              cpu: 1
              memory: 1Gi
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh","-c","ray stop"]
          ports:
          - containerPort: 6379
            name: gcs
          - containerPort: 8265
            name: dashboard
          - containerPort: 10001
            name: client
          - containerPort: 8000
            name: serve
      {% if enable_auth == "true" %}
        - name: {{deployment_id}}-rbac
          image: quay.io/brancz/kube-rbac-proxy:v0.18.1
          args:
          - "--insecure-listen-address=0.0.0.0:8265"
          - "--upstream=http://127.0.0.1:8443/"
          - "--config-file=/etc/kube-rbac-proxy/config-file.yaml"
          - "--logtostderr=true"
          volumeMounts:
          - name: config
            mountPath: /etc/kube-rbac-proxy
        volumes:
        - name: config
          configMap:
            name: {{deployment_id}}-rbac
      {% endif %}
  workerGroupSpecs:
  # NVIDIA group of GPUs
  - groupName: nvidia-group
    replicas: 0
    minReplicas: {{min_nvidia_gpus}}
    maxReplicas: {{max_nvidia_gpus}}
    rayStartParams: 
      num-gpus: "1"
    template:
      metadata:
        labels:
          kalavai.job.name: {{deployment_id}}
      spec:
        priorityClassName: {{JOB_TEMPLATE|default("user-spot-priority", true)}}
        runtimeClassName: nvidia
      {% if NODE_SELECTORS %}
        affinity:
          nodeAffinity:
            requiredDuringSchedulingIgnoredDuringExecution:
              nodeSelectorTerms:
            {% if NODE_SELECTORS_OPS == "OR" %}
              {% for selector in NODE_SELECTORS %}
              - matchExpressions:
                - key: {{selector.name}}
                  operator: In
                  values:
                  {% for vals in selector.value %}
                  - "{{vals}}"
                  {% endfor %}
              {% endfor %}
            {% else %}
              - matchExpressions:
              {% for selector in NODE_SELECTORS %}
                {% for vals in selector.value %}
                - key: {{selector.name}}
                  operator: In
                  values:
                  - "{{vals}}"
                {% endfor %}
              {% endfor %}
            {% endif %}
        {% endif %}
        containers:
        - name: ml-work-group
          image: docker.io/rayproject/ray:{{ray_version}}-py{{python_version}}-{{cuda_version}}
          imagePullPolicy: IfNotPresent
          resources:
            limits:
              nvidia.com/gpu: 1
              nvidia.com/gpumem-percentage: {{cuda_gpu_mem_percentage}}
              cpu: {{cpus}}
              memory: {{memory}}Gi
            requests:
              nvidia.com/gpu: 1
              cpu: {{cpus}}
              memory: {{memory}}Gi
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh","-c","ray stop"]
  # AMD group of GPUs
  - groupName: amd-group
    replicas: 0
    minReplicas: {{min_amd_gpus}}
    maxReplicas: {{max_amd_gpus}}
    rayStartParams: 
      num-gpus: "1"
    template:
      metadata:
        labels:
          kalavai.job.name: {{deployment_id}}
      spec:
      {% if NODE_SELECTORS %}
        affinity:
          nodeAffinity:
            requiredDuringSchedulingIgnoredDuringExecution:
              nodeSelectorTerms:
            {% if NODE_SELECTORS_OPS == "OR" %}
              {% for selector in NODE_SELECTORS %}
              - matchExpressions:
                - key: {{selector.name}}
                  operator: In
                  values:
                  {% for vals in selector.value %}
                  - "{{vals}}"
                  {% endfor %}
              {% endfor %}
            {% else %}
              - matchExpressions:
              {% for selector in NODE_SELECTORS %}
                {% for vals in selector.value %}
                - key: {{selector.name}}
                  operator: In
                  values:
                  - "{{vals}}"
                {% endfor %}
              {% endfor %}
            {% endif %}
        {% endif %}
        containers:
        - name: ml-work-group
          image: docker.io/rayproject/ray:{{ray_version}}-py{{python_version}}-{{cuda_version}}
          imagePullPolicy: IfNotPresent
          resources:
            limits:
              amd.com/gpu: 1
              cpu: {{cpus}}
              memory: {{memory}}Gi
            requests:
              amd.com/gpu: 1
              cpu: {{cpus}}
              memory: {{memory}}Gi
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh","-c","ray stop"]
---
# Authentication
# https://docs.ray.io/en/latest/cluster/kubernetes/user-guides/kuberay-auth.html
{% if enable_auth == "true" %}
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{deployment_id}}-rbac
data:
  config-file.yaml: |
    authorization:
      resourceAttributes:
        namespace: default
        apiVersion: v1
        apiGroup: ray.io
        resource: rayclusters
        name: {{deployment_id}}
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: {{deployment_id}}-rbac
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: {{deployment_id}}-rbac
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: {{deployment_id}}-rbac
subjects:
- kind: ServiceAccount
  name: {{deployment_id}}-rbac
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: {{deployment_id}}-rbac
rules:
- apiGroups: ["authentication.k8s.io"]
  resources:
  - tokenreviews
  verbs: ["create"]
- apiGroups: ["authorization.k8s.io"]
  resources:
  - subjectaccessreviews
  verbs: ["create"]
{% endif %}
# ---
# apiVersion: networking.k8s.io/v1
# kind: Ingress
# metadata:
#   labels:
#     # must have this!
#     kalavai.job.name: {{deployment_id}}
#   annotations:
#     cert-manager.io/cluster-issuer: letsencrypt-stage # use "letsencrypt-stage" for testing
#     kubernetes.io/tls-acme: "true"
#   name: {{deployment_id}}-ingress
# spec:
#   ingressClassName: traefik
#   rules:
#   - host: {{USER_ID}}-{{deployment_id}}.platform.kalavai.net
#     http:
#       paths:
#       - backend:
#           service:
#             name: {{deployment_id}}-service
#             port:
#               number: 8265
#         path: /dashboard
#         pathType: Prefix
#       - backend:
#           service:
#             name: {{deployment_id}}-service
#             port:
#               number: 6379
#         path: /gcs
#         pathType: Prefix
#       - backend:
#           service:
#             name: {{deployment_id}}-service
#             port:
#               number: 10001
#         path: /client
#         pathType: Prefix
#       - backend:
#           service:
#             name: {{deployment_id}}-service
#             port:
#               number: 8000
#         path: /serve
#         pathType: Prefix
#   tls:
#   - hosts:
#     - {{USER_ID}}-{{deployment_id}}.platform.kalavai.net
#     secretName: {{deployment_id}}.platform.kalavai.net-tls 