# {% if external_redis_url == "" %}
# apiVersion: v1
# stringData:
#   redis_password: {{redis_password}}
# kind: Secret
# metadata:
#   name: {{deployment_id}}-secret
#   labels:
#     kalavai.job.name: {{deployment_id}}
# type: Opaque
# immutable: true
# ---
# # Redis for fault tolerance
# apiVersion: v1
# kind: Service
# metadata:
#   name: {{deployment_id}}-redis-service
#   labels:
#     app: {{deployment_id}}-redis
#     kalavai.job.name: {{deployment_id}}
# spec:
#   type: ClusterIP
#   ports:
#   - name: redis
#     port: 6379
#   selector:
#     app: {{deployment_id}}-redis
# ---
# apiVersion: apps/v1
# kind: Deployment
# metadata:
#   name: {{deployment_id}}-redis
#   labels:
#     app: {{deployment_id}}-redis
# spec:
#   replicas: 1
#   selector:
#     matchLabels:
#       app: {{deployment_id}}-redis
#   template:
#     metadata:
#       labels:
#         app: {{deployment_id}}-redis
#         kalavai.job.name: {{deployment_id}}
#     spec:
#       priorityClassName: "kalavai-system-priority"
#       containers:
#       - name: redis
#         image: redis:7.4.0
#         command:
#         - "sh"
#         - "-c"
#         - |
#           redis-server --requirepass $REDIS_PASSWORD
#         ports:
#         - containerPort: 6379
#         env:
#         - name: REDIS_PASSWORD
#             valueFrom:
#               secretKeyRef:
#                 name: {{deployment_id}}-secret
#                 key: redis_password
# {% endif %}
---
# example: https://raw.githubusercontent.com/ray-project/ray/master/doc/source/cluster/kubernetes/configs/ray-cluster.gpu.yaml
apiVersion: ray.io/v1
kind: RayCluster
metadata:
  name: {{deployment_id}}
  labels:
    # must have this label
    kalavai.job.name: {{deployment_id}}
spec:
  # gcsFaultToleranceOptions:
  #   # fault tolerance https://docs.ray.io/en/latest/cluster/kubernetes/user-guides/kuberay-gcs-ft.html
  #   # example: https://github.com/ray-project/kuberay/blob/master/ray-operator/config/samples/ray-cluster.external-redis.yaml
  #   {% if external_redis_url != "" %}
  #   redisAddress: "{{external_redis_url}}"
  #   {% else %}
  #   redisAddress: "{{deployment_id}}-redis-service:6379"
  #   {% endif %}
  #   redisPassword: # <- Add redis password from a Kubernetes secret.
  #     valueFrom:
  #       secretKeyRef:
  #         name: {{deployment_id}}-secret
  #         key: redis_password
  rayVersion: "{{ray_version}}"
  autoscalerOptions:
    upscalingMode: {{upscaling_mode}}
    idleTimeoutSeconds: {{idle_timeout_seconds}}
  enableInTreeAutoscaling: true
  headGroupSpec:
    serviceType: ClusterIP
    rayStartParams:
      dashboard-host: "0.0.0.0"
      num-cpus: "0" # avoid workload on head
      num-gpus: "0"
    template: # Pod template
      metadata:
        labels:
          kalavai.job.name: {{deployment_id}}
          role: leader
      spec: # Pod spec
        terminationGracePeriodSeconds: 60
        priorityClassName: "kalavai-system-priority"
      {% if NODE_SELECTORS %}
        affinity:
          nodeAffinity:
            requiredDuringSchedulingIgnoredDuringExecution:
              nodeSelectorTerms:
            {% if NODE_SELECTORS_OPS == "OR" %}
              {% for selector in NODE_SELECTORS %}
              - matchExpressions:
                - key: {{selector.name}}
                  operator: In
                  values:
                  {% for vals in selector.value %}
                  - "{{vals}}"
                  {% endfor %}
              {% endfor %}
            {% else %}
              - matchExpressions:
              {% for selector in NODE_SELECTORS %}
                {% for vals in selector.value %}
                - key: {{selector.name}}
                  operator: In
                  values:
                  - "{{vals}}"
                {% endfor %}
              {% endfor %}
            {% endif %}
        {% endif %}
        restartPolicy: Always
        containers:
        - name: ray-head
          image: docker.io/rayproject/ray:{{ray_version}}-py{{python_version}}-cu{{cuda_version}}
          imagePullPolicy: IfNotPresent
          resources:
            # proportional to the size of the cluster (recommended 8CPU / 32GB RAM)
            limits:
              cpu: 4
              memory: 8Gi
            requests:
              cpu: 2
              memory: 4Gi
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh","-c","ray stop"]
          ports:
          - containerPort: 6379
            name: gcs
          - containerPort: 8265
            name: dashboard
          - containerPort: 10001
            name: client
          - containerPort: 8000
            name: serve
  workerGroupSpecs:
  # NVIDIA group of GPUs
  - groupName: nvidia-group
    replicas: {{min_nvidia_workers}}
    minReplicas: {{min_nvidia_workers}}
    maxReplicas: {{max_nvidia_workers}}
    rayStartParams: 
      num-gpus: "1"
    template:
      metadata:
        labels:
          kalavai.job.name: {{deployment_id}}
      spec:
        #restartPolicy: Never # for testing
        terminationGracePeriodSeconds: 60
        priorityClassName: {{JOB_PRIORITY|default("user-spot-priority", true)}}
        runtimeClassName: nvidia
      {% if NODE_SELECTORS %}
        affinity:
          nodeAffinity:
            requiredDuringSchedulingIgnoredDuringExecution:
              nodeSelectorTerms:
            {% if NODE_SELECTORS_OPS == "OR" %}
              {% for selector in NODE_SELECTORS %}
              - matchExpressions:
                - key: {{selector.name}}
                  operator: In
                  values:
                  {% for vals in selector.value %}
                  - "{{vals}}"
                  {% endfor %}
              {% endfor %}
            {% else %}
              - matchExpressions:
              {% for selector in NODE_SELECTORS %}
                {% for vals in selector.value %}
                - key: {{selector.name}}
                  operator: In
                  values:
                  - "{{vals}}"
                {% endfor %}
              {% endfor %}
            {% endif %}
        {% endif %}
        containers:
        - name: ml-work-group
          image: docker.io/rayproject/ray:{{ray_version}}-py{{python_version}}-cu{{cuda_version}}
          imagePullPolicy: IfNotPresent
          resources:
            limits:
              nvidia.com/gpu: 1
              nvidia.com/gpumem-percentage: {{cuda_gpu_mem_percentage}}
              cpu: {{cpus}}
              memory: {{memory}}Gi
            requests:
              nvidia.com/gpu: 1
              cpu: {{cpus}}
              memory: {{memory}}Gi
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh","-c","ray stop"]
  # AMD group of GPUs
  - groupName: amd-group
    replicas: {{min_amd_workers}}
    minReplicas: {{min_amd_workers}}
    maxReplicas: {{max_amd_workers}}
    rayStartParams: 
      num-gpus: "1"
    template:
      metadata:
        labels:
          kalavai.job.name: {{deployment_id}}
      spec:
      {% if NODE_SELECTORS %}
        affinity:
          nodeAffinity:
            requiredDuringSchedulingIgnoredDuringExecution:
              nodeSelectorTerms:
            {% if NODE_SELECTORS_OPS == "OR" %}
              {% for selector in NODE_SELECTORS %}
              - matchExpressions:
                - key: {{selector.name}}
                  operator: In
                  values:
                  {% for vals in selector.value %}
                  - "{{vals}}"
                  {% endfor %}
              {% endfor %}
            {% else %}
              - matchExpressions:
              {% for selector in NODE_SELECTORS %}
                {% for vals in selector.value %}
                - key: {{selector.name}}
                  operator: In
                  values:
                  - "{{vals}}"
                {% endfor %}
              {% endfor %}
            {% endif %}
        {% endif %}
        containers:
        - name: ml-work-group
          image: docker.io/rayproject/ray:{{ray_version}}-py{{python_version}}-{{cuda_version}}
          imagePullPolicy: IfNotPresent
          resources:
            limits:
              amd.com/gpu: 1
              cpu: {{cpus}}
              memory: {{memory}}Gi
            requests:
              amd.com/gpu: 1
              cpu: {{cpus}}
              memory: {{memory}}Gi
          lifecycle:
            preStop:
              exec:
                command: ["/bin/sh","-c","ray stop"]
---
apiVersion: v1
kind: Service
metadata:
  name: {{deployment_id}}-service
  labels:
    # must have this!
    kalavai.job.name: {{deployment_id}}
spec:
  type: NodePort
  selector:
    role: leader
    kalavai.job.name: {{deployment_id}}
  ports:
    - name: gcs
      port: 6379
      targetPort: 6379
      protocol: TCP
    - name: dashboard
      port: 8265
      targetPort: 8265
      protocol: TCP
    - name: client
      port: 10001
      targetPort: 10001
      protocol: TCP
    - name: serve
      port: 8000
      targetPort: 8000
      protocol: TCP
---
# Authentication
# https://docs.ray.io/en/latest/cluster/kubernetes/user-guides/kuberay-auth.html
